{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4415b6a6-e140-4db5-862d-f06a874e8fa5",
   "metadata": {},
   "source": [
    "Saved plane models are in folders `checkpoints/run_N`, where `N` is the run ID, from 0 to 9. Change the `run_id` variable to change\n",
    "Likewise, the sphere and torus data is saved as `checkpoints/sphere_run_N` and `checkpoints/torus_run_N`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e15af49e-fde4-44eb-b7cb-cf7d0e583709",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GPT2Config\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msafetensors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_file  \u001b[38;5;66;03m# Hugging Face recommends using this for .safetensors\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ContinuousGPT2\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import load_file  # Hugging Face recommends using this for .safetensors\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from transformers import GPT2Config, TrainingArguments, Trainer\n",
    "from src.model import ContinuousGPT2\n",
    "from src.collator import collate_fn\n",
    "from src.callbacks import SimpleLoggerCallback\n",
    "from datetime import datetime\n",
    "from transformers import set_seed\n",
    "with open(\"config.yaml\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "from src.dataset import MyTrajectoryDataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X0 = torch.load(f\"{cfg['data_path']}/X0.pt\")[:cfg[\"n_trajectories\"]].float()\n",
    "V = torch.load(f\"{cfg['data_path']}/V.pt\")[:cfg[\"n_trajectories\"],:cfg[\"n_velocity_steps\"],:].float()\n",
    "pos = torch.load(f\"{cfg['data_path']}/pos.pt\")[:cfg[\"n_trajectories\"], :cfg[\"n_velocity_steps\"], :].float()\n",
    "\n",
    "dataset = MyTrajectoryDataset(X0, V, pos)\n",
    "\n",
    "# Path to a specific run\n",
    "run_id = 0  # example\n",
    "checkpoint_dir = f\"checkpoints/run_{run_id}\"\n",
    "\n",
    "# Step 1: Load config\n",
    "config = GPT2Config.from_json_file(f\"{checkpoint_dir}/config.json\")\n",
    "\n",
    "# Step 2: Rebuild your model\n",
    "model = ContinuousGPT2(config, cfg[\"num_x_tokens\"], cfg[\"x_dim\"], cfg[\"v_dim\"], cfg[\"y_dim\"])\n",
    "\n",
    "# Step 3: Load the weights\n",
    "state_dict = load_file(f\"{checkpoint_dir}/model.safetensors\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()  # Don't forget this if you're testing!\n",
    "\n",
    "# Step 4: Load a test sample (example: first one in your dataset)\n",
    "test_sample = dataset[0]\n",
    "x_inputs = test_sample[\"x_inputs\"].unsqueeze(0)  # Add batch dim\n",
    "v_inputs = test_sample[\"v_inputs\"].unsqueeze(0)\n",
    "attention_mask = torch.ones((x_inputs.size(0), 3 + v_inputs.size(1)))\n",
    "pos_inputs = test_sample[\"labels\"].unsqueeze(0)\n",
    "\n",
    "# Step 5: Run forward pass (assuming your model has a forward(x_inputs, v_inputs))\n",
    "with torch.no_grad():\n",
    "    output = model(x_inputs, v_inputs, attention_mask, pos_inputs)\n",
    "\n",
    "print(\"Model output:\", output['logits'])\n",
    "print(\"Model loss:\", output['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a719d3-8ca4-4169-a8fe-42f15f80f6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
